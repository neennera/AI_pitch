{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 960x640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "figure(figsize=(12, 8), dpi=80)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSICNET_DIR = \"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\"\n",
    "wav_paths = sorted(glob(f\"{MUSICNET_DIR}/*.wav\", recursive=True))\n",
    "save_path = \"D:\\\\AI_MIDI\\\\processed\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง classmap ระหว่างโน๊ตและ index เพื่อให้ง่ายต่อโมเดล\n",
    "df = pd.read_csv(\"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\labels.csv\")\n",
    "classm = df[\"note\"].unique().tolist()\n",
    "classmap=[]\n",
    "for i in range(0,10):\n",
    "    for c in 'CDEFGAB':\n",
    "        if (c+str(i) in classm) :\n",
    "            classmap.append(c+str(i))\n",
    "        if (c+'#'+str(i) in classm) :\n",
    "            classmap.append(c+'#'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26643 entries, 0 to 26642\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   wav_path    26643 non-null  object\n",
      " 1   duration    26643 non-null  int64 \n",
      " 2   instrument  26643 non-null  object\n",
      " 3   key_number  26643 non-null  int64 \n",
      " 4   note        26643 non-null  object\n",
      " 5   label       26643 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0', 'A#0', 'B0', 'C1', 'C#1', 'D1', 'D#1', 'E1', 'F1', 'F#1', 'G1', 'G#1', 'A1', 'A#1', 'B1', 'C2', 'C#2', 'D2', 'D#2', 'E2', 'F2', 'F#2', 'G2', 'G#2', 'A2', 'A#2', 'B2', 'C3', 'C#3', 'D3', 'D#3', 'E3', 'F3', 'F#3', 'G3', 'G#3', 'A3', 'A#3', 'B3', 'C4', 'C#4', 'D4', 'D#4', 'E4', 'F4', 'F#4', 'G4', 'G#4', 'A4', 'A#4', 'B4', 'C5', 'C#5', 'D5', 'D#5', 'E5', 'F5', 'F#5', 'G5', 'G#5', 'A5', 'A#5', 'B5', 'C6', 'C#6', 'D6', 'D#6', 'E6', 'F6', 'F#6', 'G6', 'G#6', 'A6', 'A#6', 'B6', 'C7', 'C#7', 'D7', 'D#7', 'E7', 'F7', 'F#7', 'G7', 'G#7', 'A7', 'A#7', 'B7', 'C8', 'C#8', 'D8', 'D#8', 'E8', 'F8', 'F#8', 'G8', 'G#8', 'A8', 'A#8', 'B8', 'C9', 'C#9', 'D9', 'D#9', 'E9', 'F9', 'F#9', 'G9']\n"
     ]
    }
   ],
   "source": [
    "print(classmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test assign\n",
    "df['train'] = np.zeros(26643) == 0\n",
    "for note in df[\"note\"].unique():\n",
    "    index = df.index[df['note'] == note].tolist()\n",
    "    choices = random.sample(index, k= int(0.2*len(index)))\n",
    "    for id in choices:\n",
    "        df['train'][id]=False\n",
    "\n",
    "count = np.zeros((2,107), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA_Prepare():\n",
    "    def __init__(self, transformation, device):\n",
    "        self.MUSICNET_DIR = \"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\"\n",
    "        self.target_sample_rate = 16000.0\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.wav_paths = sorted(glob(f\"{self.MUSICNET_DIR}/*.wav\", recursive=True)) \n",
    "        self.count_path = len(wav_paths)\n",
    "\n",
    "    def get_data(self,st,ed) :\n",
    "        for i in range(st,ed):\n",
    "            if i == self.count_path :\n",
    "                return i\n",
    "            wav_path = self.wav_paths[i]\n",
    "            signal, sr = torchaudio.load(wav_path)\n",
    "            signal = self._resample_if_necessary(signal, sr)\n",
    "            signal = self._mix_down_if_necessary(signal)\n",
    "            signal = self.transformation(signal)\n",
    "            if (wav_path[38]!='_') :\n",
    "                label = classmap.index(wav_path[36:39])\n",
    "            else :\n",
    "                label = classmap.index(wav_path[36:38])\n",
    "                    \n",
    "            self.save_data(signal,label,i)\n",
    "            with open(\"dump_i.txt\", \"wb\") as f:\n",
    "                pickle.dump(i+1,f)\n",
    "            with open(\"dump_count.npy\", \"wb\") as f:\n",
    "                pickle.dump(count,f) \n",
    "        return ed+1\n",
    "\n",
    "    def save_data(self,signal,label,i):        \n",
    "        datatype = \"train\" if df[\"train\"][i] else \"test\"\n",
    "        #label-count\n",
    "        ty = 1*(datatype == 'train')\n",
    "        if len(str(count[ty][label])) == 1 :\n",
    "            ct = '0'+str(count[ty][label])\n",
    "        else :\n",
    "            ct = str(count[ty][label])\n",
    "        count[ty][label]+=1\n",
    "\n",
    "        #label\n",
    "        if len(str(label))==1:\n",
    "            label = '0'+str(label)\n",
    "        else :\n",
    "            label = str(label)\n",
    "\n",
    "        with open(f\"{save_path}/{datatype}/{label}-{ct}.npy\", \"wb\") as f:\n",
    "            np.save(f, signal.numpy())\n",
    "    \n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def get_spectro(self,wav_path):\n",
    "        signal, sr = torchaudio.load(wav_path)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump_count.npy\", 'rb') as f:\n",
    "    count = pickle.load(f)\n",
    "with open(\"dump_i.txt\", 'rb') as f:\n",
    "    i = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"instrument\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[(df[\"instrument\"] == \"ACOUSTIC_GRAND_PIANO\") & (df[\"note\"] == \"G7\")].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180f0f427f0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = feat.get_spectro(\"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\\\\\"+df2[\"wav_path\"][0]+'.wav')\n",
    "import seaborn as sns\n",
    "sns.heatmap(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=34624,\n",
    "    n_mels=254,\n",
    "    n_fft=2048,\n",
    "    hop_length=512\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "feat = DATA_Prepare(mel_spectrogram, device)\n",
    "i = feat.get_data(i,len(wav_paths))\n",
    "print(f\"done {i} in {len(wav_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "id = 64\n",
    "print(classmap[data[id][\"label\"]])\n",
    "sns.heatmap(data[id][\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def sample_to_frames(\n",
    "    t_sample,\n",
    "    frame_size=10, # ms / frame\n",
    "    sampling_rate=44100\n",
    "):\n",
    "    t_sec = t_sample / sampling_rate  # (sample) / (sample / sec)\n",
    "    t_frame = t_sec / (frame_size / 1000) # (sec) / (sec / 1000*frame)\n",
    "    return int(t_frame)\n",
    "\n",
    "\n",
    "def get_data(set_name=\"train\", n_notes=88):\n",
    "    # check if set_name is valid or not\n",
    "    if set_name.lower().strip() not in [\"train\", \"test\"]:\n",
    "        raise NameError(f\"Unrecognized set name: {set_name}\")\n",
    "    \n",
    "    wav_paths = sorted(glob(f\"{MUSICNET_DIR}/{set_name}_data/**/*.wav\", recursive=True))\n",
    "    csv_paths = [wav.replace(\"_data\", \"_labels\").replace(\".wav\", \".csv\") for wav in wav_paths]\n",
    "    #print(csv_paths)\n",
    "    assert all(os.path.exists(csv) for csv in csv_paths)\n",
    "    \n",
    "    data = []\n",
    "    for wav_path, csv_path in tqdm(zip(wav_paths, csv_paths), total=len(wav_paths)):\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        # config feature here\n",
    "        fbank = kaldi.fbank(wav, sample_frequency=sr, num_mel_bins=120, frame_length=30)\n",
    "        \n",
    "        label = pd.read_csv(csv_path)\n",
    "        y = np.zeros([fbank.shape[0], n_notes])\n",
    "        for  i, row in label.iterrows():\n",
    "            y[sample_to_frames(row[\"start_time\"]):sample_to_frames(row[\"end_time\"]), row[\"note\"] - 20] = 1\n",
    "            \n",
    "        data.append({\"wav_path\": wav_path, \"label\": y, \"feature\": fbank})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSoundDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n",
    "        path = os.path.join(self.audio_dir, fold, self.annotations.iloc[\n",
    "            index, 0])\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "There are 8732 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ANNOTATIONS_FILE = \"D:\\\\AI_pitch_Data\\\\UrbanSound8K\\\\metadata\\\\UrbanSound8K.csv\"\n",
    "    AUDIO_DIR = \"D:\\\\AI_pitch_Data\\\\UrbanSound8K\\\\audio\"\n",
    "    SAMPLE_RATE = 22050\n",
    "    NUM_SAMPLES = 22050\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device {device}\")\n",
    "\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
    "                            AUDIO_DIR,\n",
    "                            mel_spectrogram,\n",
    "                            SAMPLE_RATE,\n",
    "                            NUM_SAMPLES,\n",
    "                            device)\n",
    "    print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "    signal, label = usd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(usd, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CNNNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(128 * 5 * 4, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CNNNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
    "  for inputs, targets in data_loader :\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "  \n",
    "  #calculate loss\n",
    "  pred = model(inputs)\n",
    "  loss = loss_fn(pred, targets)\n",
    "  #acc = Acc_fn(pred, targets)\n",
    "\n",
    "  #backpropagate + update weight\n",
    "  optimiser.zero_grad() #ลบ gradiun จาก batch ก่อนๆ\n",
    "  loss.backward()\n",
    "  optimiser.step()\n",
    "\n",
    "  print(f\"Loss : {loss.item()}\") #\\t Acc:{acc}\")\n",
    "\n",
    "def train(model, data_loader, loss_fn, optimiser, device, epoch):\n",
    "  for i in range(epoch):\n",
    "    print(f\"Epoch : {i+1}\")\n",
    "    train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
    "    print(\"---------------------------\")\n",
    "  print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataloader, loss_fn, optimiser, device, epochs)\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Trained feed forward net saved at feedforwardnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9bf447bc3f95dcfbc19cb1a84d6b160112105653e59c16eb73ab72854d9f644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
