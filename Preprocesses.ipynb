{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 960x640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "figure(figsize=(12, 8), dpi=80)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSICNET_DIR = \"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\"\n",
    "wav_paths = sorted(glob(f\"{MUSICNET_DIR}/*.wav\", recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง classmap ระหว่างโน๊ตและ index เพื่อให้ง่ายต่อโมเดล\n",
    "df = pd.read_csv(\"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\labels.csv\")\n",
    "classm = df[\"note\"].unique().tolist()\n",
    "classmap=[]\n",
    "for i in range(0,10):\n",
    "    for c in 'CDEFGAB':\n",
    "        if (c+str(i) in classm) :\n",
    "            classmap.append(c+str(i))\n",
    "        if (c+'#'+str(i) in classm) :\n",
    "            classmap.append(c+'#'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34624"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_path = wav_paths[0]\n",
    "sr = 16000.0\n",
    "wav, _ = torchaudio.load(wav_path)\n",
    "fbank = kaldi.fbank(wav, sample_frequency=sr, num_mel_bins=120, frame_length=30)\n",
    "if (wav_path[38]!='_') :\n",
    "    label = str(classmap.index(wav_path[36:39]))\n",
    "else :\n",
    "    label = str(classmap.index(wav_path[36:38]))\n",
    "if len(label)==1:\n",
    "    label = '0'+label\n",
    "\n",
    "len(wav[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSICNET_DIR = \"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\"\n",
    "class DATA_Prepare():\n",
    "    def __init__(self, transformation, device):\n",
    "        self.MUSICNET_DIR = \"D:\\\\AI_MIDI\\\\midisynth_dataset-v1\\\\wav\"\n",
    "        self.target_sample_rate = 16000.0\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "\n",
    "    def get_data(self) :\n",
    "        wav_paths = sorted(glob(f\"{self.MUSICNET_DIR}/*.wav\", recursive=True))      \n",
    "        data=[]\n",
    "        for wav_path in wav_paths:\n",
    "            print(wav_path)\n",
    "            signal, sr = torchaudio.load(wav_path)\n",
    "            signal = self._resample_if_necessary(signal, sr)\n",
    "            signal = self._mix_down_if_necessary(signal)\n",
    "            signal = self.transformation(signal)\n",
    "            if (wav_path[38]!='_') :\n",
    "                label = classmap.index(wav_path[36:39])\n",
    "            else :\n",
    "                label = classmap.index(wav_path[36:38])\n",
    "                    \n",
    "            data.append({\"data\": signal,\"label\": label})\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    " mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=34624,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "feat = DATA_Prepare(mel_spectrogram, device)\n",
    "data = feat.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D#4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23299042d00>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD9CAYAAAB3ECbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de7xdVXXvv79zTp5AAkkkQpIawKAFrQ9ipPW2oCjEooRepUbbQi01llLFXiuPcu+lvbdY8IWihY9peavE8BBiFRRB8HMrEBDREAISw+uQB6+QBwlJztnj/rHmISt7zb3XWufsfc7e+4zv+czPXnusMdeca+195l5rzDHHkJnhOI7jtAddI90Bx3Ecpzg+aDuO47QRPmg7juO0ET5oO47jtBE+aDuO47QRPmg7juO0ET5oO47jtBE+aDuO47QRPXkKkt4ILABmAAasBZaZ2apCDYyd4at3HMcpRN/OZzTUY+x6fk3hMWfMtIOH3N5wU/dOW9JZwBJAwHLgvrB9raSz69RbJOl+SfdXKi83sr+O4zj1qfQXL22I6i1jl/Qb4HAz21UlHwusNLM5eQ34nbbjOEVpyJ32hkeL32lPf0Pb3WnnmUcqwIHAk1XyA8I+x3Gc1qLS2UNT3qD9GeB2SY8BTwfZ7wCvB/6umR1zHMcZDNbfN9JdaCp1B20zu1XSocA8kolIAb3AfWbWngYhx3E6Gxvdd9qYWQW4Zxj64jiOM3TadIKxKLmDtuM4Tlsx2u+0Hcdx2opRPhHpOI7TVozqiUjHcZy2w80jjuM4bYRPRDqO47QRHX6nXTrKn6Srm9ERx3GchlCpFC85SLpc0rOSHqqSf0rSo5JWSvpCSn6OpNVh33Ep+RGSVoR9F0tSkI+T9N0gv1fS7Lw+1b3TlrSsWgS8W9K+AGZ2Ql4DjuM4w0pj77SvBL4BvHqzKundJJFPf8/MdkjaP8gPAxYCh5OE//iJpEPDQsRLgUUka15+CMwHbgFOBTaa2eslLQQuBD5Sr0N55pGZwMPAf5CEZRUwF/hyvUqSFoUOou7JdHXtldOM4zhOY7D+XflKRY9l9rPI3e9pwAVmtiPoPBvkC4AlQf64pNXAPElPAJPM7G541VpxIsmgvQD4p1D/euAbkmR1IvnlmUfmAr8AzgU2mdmdwHYzu8vM7qpzoovNbK6ZzfUB23GcYcUqhUs6jHQoiwq0cCjwh8GccZekdwT5DHbHaIIk5MeMUHoj8j3qmFkfsAmYWq/xvNgjFeAiSdeF1w15dRzHcUaUEotrzGwxsLhkCz3AfsCRwDuApZIOJrFEZJqoIydnX83GczGzXuAkSccDm4vUcRzHGRGa7z3SC9wYTBjLJVWAaUE+K6U3kyTTV2/YrpaTqtMrqQeYDLxYr/FS3iNm9gMz+8cydRzHcYaV5meuuQl4D0CIgjoWeB5YBiwMHiEHAXOA5Wa2Dtgi6cjgNXIycHM41jLglLD9YeCOevZscFOH4zidRgOXsUu6FjgamCapFzgPuBy4PLgB7gROCQPtSklLSZw3+oDTUyGsTyPxRJlAMgF5S5BfBlwTJi1fJPE+qd+nnEF9yHi6McdxitKIdGOv3H1t4TFn/O9/tOPSjTmO47QXHuXPcRynjfBB23Ecp33o9EyIPmg7jtNZ+J224zhOGzGakyBIGkvigrLWzH4i6WPAHwCrgMVm1rhF/o7jOI2gw0Oz5t1pXxF0Jko6BdgbuBE4BpjHbqfwPfCAUY7jjBij3DzyZjP7vbC88hngQDPrl/Qt4Fe1KqXX87uftuM4w8oov9PuCiaSvYCJ7F4XPw4Y0+S+OY7jlGeU32lfBjwCdJOEZ71O0hqS6FZLmtw3x3Gc8ozmQdvMLpL03bC9NgTvfi/w72a2fDg66DiOU4rR7D0CyWCd2n6JJLuC4zhOazLKbdqO4zjtxWg2jziO47QdfqfdenQpHk2xu6s7I+uL2Lca4YNYOkeQ01GUiefp34thxu+024PYgN0s2i4Ar+OMJvo7O2BUqXRjjuM4LU+lUrzkIOlySc+GLDXV+/5BkkmalpKdI2m1pEclHZeSHyFpRdh3cUg7RkhN9t0gv1fS7Lw++aDtOE5n0cBBmyRF2PxqoaRZwPuAp1Kyw0hiNR0e6lwiacAEcClJaI85oQwc81Rgo5m9HrgIuDCvQ21pHjly2hsysh8v+cuobvfvvisj2/Hlz0V1bdO2rHBs9hL1vDnbPgDjxmVlr2zPiCprN0Srb/1pb0bWVeITGn/4pIys/7mXM7Ida+OPj9s3js3IamWjG79Pdq6g0p81HO3aHjdbPf98Nh7NvpOy12qvKTuj9bt6sh3b8mz2+q99MXtNALZZtl+TurLxzw46JJ4Ye9zU7D/8c49OjOo+uGlKtl9jstdqi+IXe0olq/t0d/Yz/N7Lj0XrP/Py8xnZzr7suXaM7b2BE5Fm9rMad78XAWeyO0EvwAJgiZntAB4PeR/nSXoCmGRmdwOE9S4nkuSJXAD8U6h/PfANSaqX3NfvtB3H6SxK3GlLWiTp/lRZlHd4SScAz5hZdfylGcDTqfe9QTYjbFfL96hjZn3AJmBqvfabcqftUf4cxxkxSiQrTwe3K4KkiSQhPY6N7Y41UUder05N8uJpTwLOAWYCt5jZd1L7LjGzv43Va3aUv99uW5+RHXLCBfzLxLdl5H84+VsZWcXi/h9jx2UfOZMfvz3ZeevKaP2enuxjWc/Y7DH7d8UfcJ57IfsD21fJ6vZ0xR//XrN+a0a245XxGdmGzfEf0Z1kTQbdNb4/4zdEzivy/eurca33HbsjI9uyNdvX1S/sF63/9JjsV3dr5LJOqvENf+2ubP9frmSVb18zIyMDWPN09ro8q/jy6dj3at+IeWZijWv1Yle2rccsa/Z6ccfmaP1dTXJ7bVn6mrqM/RDgIOBXYS5xJvCApHkkd9CzUrozgbVBPjMiJ1WnN0RTHQjKV5M888gVJL8ENwALJd0gacBweGRO3WElNmA7jjMKsUrxUvbQZivMbH8zm21ms0kG3beb2XpgGck4OU7SQSQTjsvNbB2wRdKRwWvkZHbbwpexOy/Bh4E76tmzId88coiZfShs3yTpXOCOYNNxHMdpOazSuOcISdcCRwPTJPUC55nZZdF2zVZKWgo8DPQBp9vuLMOnkXiiTCCZgLwlyC8DrgmTli+SeJ/UJW/QHiepyyz5STKz80PHf0aSxcZxHKe1aOCKSDP7aM7+2VXvzwfOj+jdD7wpIn8FOKlMn/IG7e8D7wF+kmrkKkkbgK+XaaiRbHj5pYzsEy//NK78XJM700pkPbscZ/QxmmOPmNmZNeS3Svp8c7rkOI4zBBpoHmlFhuKn/c8N64XjOE6j6OsrXtqQPJe/X9faBUxvfHccx3GGSAk/7XYkz6Y9HTgO2FglF/DzpvTIcRxnKIzy0Kz/CextZg9W75B0Z1N65DiOMxQ63KadNxF5ap19H2t8dxzHcYbIaPYecRzHaTesr7OTIJQetCVNNbMXmtEZx3GcIdPh5pG6Ln+SLhjIyiBprqQ1wL2SnpR0VJ16r4Y7rFSygW0cx3GaRhNjj7QCeX7ax5vZwDq7LwIfCRkW3gd8uVYlM1tsZnPNbK6HZXUcZ1ipWPHShuSZR8ZI6gnBuSeY2X0AZvabVLQ/x3Gc1mGUu/z9G/BDSRcAt0r6KnAjcAyQcQN0HMcZcdr0DrooeS5/X5e0giSs4KFB/1DgJuD/Nr97juM4Jekf5d4jZnYncGe1XNLHSZIkOI7jtAzW4eYRDxjlOE5n0eETkXkuf7+uUVbgAaMcx2lFGjhoS7pc0rOSHkrJvijpkTAWfk/Svql950haLelRScel5EdIWhH2XRzSjhFSk303yO+VNDuvT3l32tNJ8pl9MFJ8gY0zalGJ4gwzjfXTvhKYXyW7DXiTmf0e8BuS5OdIOowkXdjhoc4lkgYyOF8KLCLJGzkndcxTgY3Blfoi4MK8DuUN2gMBo56sKk8QsXM7juOMOA280zazn1GVHd3MfhzcoAHuYXem9QXAEjPbYWaPA6uBeZIOACaZ2d0hae/VwImpOleF7euBYwbuwmvhAaMcx+korK/4RKSkRSR3wAMsNrPFJZr7K+C7YXsGySA+QG+Q7Qrb1fKBOk8DmFmfpE3AVOokD2zLgFHje8ZmZG/Z76Co7oKeAzOyd+14Jaq7z/gdGdmvd07OyB4ZG/9SbCbravQay17i11TiP6Q7IuInu7LZNTayK1p/k2XlWys7M7JdFneJ6os8Lm6P1K/FhK7s5zKha0xUtztiOBiv7LUa/+rT5Z6Mjchjj43bapzrFsue15jIEQ7uiuevntOf7ev2GvdHD3Vtz8ie6c+Gd4hdE4DXdk/MyGKf9fIta6L1X9i+JSPb1d+eWVsKUcJ7JAzQZQbpV5F0LknW9W8PiGJN1JHXq1OTthy0HcdxajIMXiGSTgE+ABwTTB6Q3EHPSqnNBNYG+cyIPF2nV1IPMJkqc0w1ed4jk0PQqEckvRDKqiDbt049DxjlOM7I0GSXP0nzgbOAE8xsW2rXMmBh8Ag5iGTCcbmZrQO2SDoy2KtPBm5O1TklbH8YuCP1IxBvv95+ST8C7gCuMrP1Qfba0Mh7zex9eSfYM3ZGw3/2urvivzUz9p6Wkb19r1kZ2WHaJ1p/XKSn65R9jNxgcfNKzLwQe7yfEDEDAFjkqWhL5DEYYHPEbLHTsn19pRJ/DI7p9kVMCbsqxVeXjenKnuv4iMkEYN/uCRmZIk+K22qYZ16uZE1Z3cp+LyYobp6JmXJi1x9geyX7GeyIXL9KDW+Ensh3YHxX9juwT9f4aP1Yv57eWZ0BEFZvXpuRAezsy/a/VT2U+3Y+M2SHm82fPK7w6U365o/qtifpWuBoYBqwATiPxFtkHLs96O4xs78J+ueS2Ln7gM+Y2S1BPpfEE2UCcAvwKTMzSeOBa4C3kdxhLzSzuJ0rkGcemW1me7ighMH7Qkl/lVN3WIkN2J1KbMAuQ2zAduLEBmynxSkxEZmHmX00Ir6sjv75wPkR+f3AmyLyV4CTyvQpz+XvSUlnSnp1IY2k6ZLOIsx4Oo7jtBJWscKlHckbtD9C4n5yl6SNkl4k8c+eAvxpk/vmOI5Tng5fxp7np71R0hUkK4DuMbOtA/uCMf7WJvcvSn/Epeepzc9GdWPymxreI8dxWobOjheV6z3yaZJZzr8DHpK0ILX7883smOM4zmDodPNI3kTkJ4AjzGxrCGRyvaTZZvY1PKyC4zitSJsOxkXJG7S7B0wiZvaEpKNJBu7X4YO24zgtiPV19qCdNxG5XtJbB96EAfwDJD6Lb25mxxzHcQZFpURpQ/LutE8mcRJ/lRDd6mRJ32xarxzHcQZJu9qqi5LnPdJbZ99/Nb47juM4Q6RN76CLUjpglKT9zSzuX+c4jjPCFMtt0L7UHbQlTakWAcslvY0kbkndaFSO4zjDTadHaci7034eeLJKNgN4gCTmzMGxSunA4uqeTFfXXkPspuM4TkFG8502cCbwXuBzZrYCQNLjZhbPOBBIBxZvRpS/MrhfYmtS9EtR6/PrjkQUjEXDq9QIiF+0/Z5IOwB7j81G5KvUiJi5dWc2CUIt3aKU+V539rRcllFtHjGzL0laAlwk6WmSsISj7TvgOE4bMaoHbXjVg+QkSR8kiUGSzX3kOI7TIoz6QVvSG0ns2D8FfgIcEuTzzWxEAkbVSoKw3/hsPr+3T8pacrprrCma0jUuI5scuUSTqPHIbHlrlRK2Kv6tGmfZh95dkefgnhrPOrFebVdcuSvygN0VUY2fKYwr+IAeOybAjki/xkSOGUtMATAmIo9dq001zj92XfaOXH+A2ZED79ufTQ7xQk/8aq2P/JftKvHAujXS10d3x257lbs3rY7Wf2lHNntUXyRHZMc8Qtf4HDuFogGjPgU8BBxrZg+F3S0VMCo2YDtxYgO2Eyc2YDutTaVPhUseki6X9Kykh1KyKZJuk/RYeN0vte8cSaslPSrpuJT8CEkrwr6LQ9oxQmqy7wb5vSHGU13ybg0HAkadSJJy539JOmOgH7ln7DiOM8xYpXgpwJXA/CrZ2cDtZjYHuD28R9JhwELg8FDnEunVXHOXknjUzQll4JinAhvN7PXARcAemcJi5A3aewSMIhm43y/pK/ig7ThOC2KmwiX/WPYzstnRFwBXhe2rgBNT8iVmtsPMHgdWA/MkHQBMMrO7Q9Leq6vqDBzreuCYgbvwWuTZtNdLequZPRhOYKukDwCXM4IBo2JJEF7Ytjmqe8crD2Vkta5JV0Qec/mKJZBtVWLnVIuYG1qt+YOhmljG92QT6/ZHbn1e6Yvnw9wekccSA4/viSf2ndiTnb+oRKy6L72StQcD7Owvnjsydq6TxmXn8yd0Z/sEsHlntg+bI26EuyJ26tFImYnI9JqSwOLgslyP6SHDOma2TtL+QT4DuCel1xtku8J2tXygztPhWH2SNpFkC3u+VuMeMMpxnI7CKsVvKNJrShpArGGrI69XpyZ1bxnNrDdkX4/t84BRjuO0HGbFyyDZEEwehNeBWEy9wKyU3kxgbZDPjMj3qCOpB5hM1hyzB6UDRrUqta5/XyXrmlWGHRR/DHZaj1rmlZeImz2awbZdOwrJnMZQ6Wu6+XIZcApwQXi9OSX/TpjzO5BkwnG5mfVL2iLpSOBeEgvG16uOdTfwYeCOYPeuSccM2o7jODCkO+gMkq4lccCYJqmXZFX4BcBSSacCTwEnJe3aSklLgYdJzMqnm9nAXeNpJJ4oE4BbQgG4DLhG0mqSO+yFuX2qN6hLmgt8EXgGOIdkAnIe8BtgkZn9ska9dMCoIzxglOM4Rejb+cyQvdLWvPnYwsP2wSt+3HZecHnPEZcAXwB+APwc+KaZTSbxS7ykViUzW2xmc81srg/YjuMMJ410+WtF8gbtMWZ2i5ldC5iZXU+ycTuQDXPmOI4zwjR4cU3LkWfTfkXSsSQzmibpRDO7SdJRwNBm+BzHcZpAf6V91lEMhrxB+29IzCMV4DjgNElXkti4P9HcrjmO45SnjJ92O5IXT/tXkj5D4r7Sa2ZnAGdAEuVvGPpXmFofU1eNFX0xYgHzYzMatVYZxlZaxlbpVWo8l+WsXs0lNqkcO2aOR9GgGem2ylC0X7XaiX2uNduKfIti7dfqU9FzHWpihU6h0y9DkSh/3yNE+ZO0ILW7paL8OY7jQHKnXbS0I3nmkU8Ac0PMkdnA9ZJmm9nX8IBRjuO0IJU29QopSt6gvUeUP0lHkwzcr6PFBu1aC/yb0tYQH2ObRdH2h7OfZcwLMTNCLYqagsr2q2hbZfpatP2h9slJaFdXvqLkGXzXS3rrwJswgH8AmMYIRvmL0dkfkzNS+ODYfvRXVLi0Ix7lz3GcjqLT77TzvEd66+zzKH+O47Qcnf5w1DEBo2p9TrGECS3bVqd/25pNO12/duprmzHaJyIdx3Haik43j+T5aU+S9K+SrpH0sap9NQNGSVok6X5J91cqwxe32HEcp2IqXNqRPO+RK0gcM24AFkq6QdJAIrsja1XyKH+O44wU/abCpR3JM48cYmYfCts3SToXuEPSCU3ul+M4zqAY1eYRYJy0O/W4mZ1PkgTzZyQZgx3HcVqKSomSh6S/l7RS0kOSrpU0XtIUSbdJeiy87pfSP0fSakmPSjouJT9C0oqw72INYYVb3qD9feA9aYGZXQV8Fogn33McxxlBDBUu9ZA0A/g0SSiPNwHdJOnAzgZuN7M5wO3hPZIOC/sPB+YDl0jqDoe7lCSb15xQBh1wL89P+0xJ8yS9w8zuC52aDzwSOtyWlPmJG2rkujJRBmOUaatolMFWZahLw4dK7Fo1Ysn/UFdV1ooKmdVzN0KASmMvQw8wQdIuYCJJFvVzSPJGAlwF3AmcBSwAlpjZDuDxkPdxnqQngElmdjeApKuBE9mdJ7J0h2oi6Tzg/UCPpNuAd4YOni3pbcFc4jiO0zL05xoQdpPOZxtYbGaLAczsGUlfIkneux34sZn9WNJ0M1sXdNZJ2j/UnQHckzpWb5DtCtvV8kGRNxH5YeCtwDhgPTDTzDZL+iJJKngftB3HaSnKLHELA/Ti2L5gq14AHAS8BFwn6c/rHC72WFYrlt2gnwfyBu2+kAJ+m6TfmtlmADPbLqlNM6yVu1pDfbRtxorMmhQN7F+r+hCbb4YhplkP/EX7OtLtN7MPnUqerboE7wUeN7PnACTdCPwBsEHSAeEu+wDg2aDfC8xK1Z9JYk7pDdvV8kGR9xyxU9LEsH3EgFDSZMr9oDmO4wwLDfQeeQo4UtLE4O1xDLAKWAacEnROAW4O28tI1rOMk3QQyYTj8mBK2SLpyHCck1N1SpN3p/1HwaiO2R6zIWNSnXYcx2kZGnU3aWb3SroeeIAk2ukvSUwpewNLJZ1KMrCfFPRXSloKPBz0Tw+WCoDTgCuBCSQTkIOahARQs+MF94yd4U93TscRyxNay9NkWE1kbU7fzmeGbNv4wfSPFh5zjt9wbfu4VwVKB4ySNNXMXmhGZxzHcYZK3whnkGo2eQGjLpA0LWzPlbQGuFfSk5KOGpYeOo7jlMBKlHYkbyLyeDN7Pmx/EfiImb0eeB/w5VqVPMqf4zgjRSOXsbcieeaRMZJ6QoqxCWZ2H4CZ/SYV7S9D2vexGTbt10ycnJFNHTcprjtmn4ysq4ZLUMwmeWh3tq05lbHR+j2RM32hKytcp3gEgL3ozsgOrGQ/olqp7X6rHRnZ+Mgxx9Q4/w2Wrb+2f2tUd3PllYysP7Jyr9acSSVynzOhK3tdJ3dPiNbfp2tM5JhZXq7sitbfVsl+BhMj7c/u3jtaf7NljztL8b5upT8jezkiW9cfv8EZq+xnGLt+y19aHa2/ece2bP0OXj1Z6XDzSN6g/W/ADyVdANwq6avAjSSuLw82u3OO4zhl6dyfo4S82CNfl7SCxF3l0KB/KHAT8C/N757jOE452tXsUZQi3iPbgC+FgFED0at6zSLPh8PE89s2ZWSbd2YfAQGe6Xo+I6vlmhVz41rVnX0MH98dtwzF6vdV+jKyXZZ9NAboVnaKYWzEDFCLHf3ZR/7YMWsR69eO/vjHHHNjK+M+Ora7mONSzOQCsLM/e11jjOuJX7+xXdn2Y9+L5TuzZiCAl3dl5bW+V5PGTczI9h0bN7vE2NaXbWvLzu1ZvV1Z89ZopNO9R8oGjJoH3IUHjHIcp0UZ1eYRPGCU4zhtRq2J+k5hVAaMchync+n0gSlv0N4paaKZbaOFAkbFHn929MVtrzsYMdO70wIMq523hk1/4/as22RM5jSG0W4e8YBRjuO0FX2j2TwyMGBH5M8DWbcMx3GcEWa0m0ecDqQTbkSa8QjcTtel000AQ8Ha6YMcBD5oO47TUXT6nXZelL/JIdLfI5JeCGVVkO1bp54HjHIcZ0To9IBRecvllgIbgaPNbKqZTQXeHWTX1apkZovNbK6Zze3q2qtxvXUaQpnQla1amsFIn9NIn3+n0MjrKGlfSdeHG9dVkn5f0hRJt0l6LLzul9I/R9JqSY9KOi4lP0LSirDvYtVaPluAvEF7tpldaGbrBwRmtt7MLgR+Z7CNOo7jNIs+FS8F+Bpwq5m9EXgLSY7Is4HbzWwOcHt4j6TDgIXAQLiPS6RXQzReCiwiyRs5J+wfFHmD9pOSzpQ0fUAgabqks4CnB9uo4zhOs2iUeUTSJOCPgMsAzGynmb0ELACuCmpXASeG7QXAEjPbYWaPA6uBeSFj+yQzu9uSAD1Xp+qUJm/Q/ggwFbhL0kZJG4E7g+xPB9uo4zhOs2igeeRg4DngCkm/lPQfkvYCpocM64TX/YP+DPa8me0Nshlhu1o+KPL8tDcCZ4UCgKRrzOzMwTY43MQi73V3ZYPKA1RqRJTLHjP+WxdrK4ZqOJdZ5GsUjaZX4+sWi7IXleV1sA2IXcFOOC9n6JSJPSJpEYnZYoDFIYkLJOPj24FPhczsXyOYQmodLiKzOvJBkRflb1lE/J4BuZmdMNiGHcdxmkEZr5B0lq0IvSRhqO8N768nGbQ3SDrAzNYF08ezKf1ZqfozgbVBPjMiHxR5ftozgYeB/2D3L8Y7qJMf0nEcZyRp1BOXma2X9LSkN5jZoyQZux4O5RTggvB6c6iyDPiOpK8AB5JMOC43s35JWyQdSRId9WTg64PtV96gPRc4AzgX+JyZPShpu5ndNdgGh5tYLjyrEUA/9mHHnmsqI+zh6WYAvwZObfoa++34FPBtSWOBNcDHSeYCl0o6FXgKOAnAzFZKWkoyqPcBp4coqZBk/7oSmADcEsqgUJFsI5JmAhcBG4ATzKywu18zEvsOlVomr6KD9kjTchfUcRpE385nhvwv939e92eF/0X+95PfbsV/8boUWsZuZr3ASZKOBzY3t0uO4ziDp11XOhalVOwRM/sB8IMm9cVxHGfIjPbMNRkk7W9mz+Zrti5lzAtuinCc9qLS4f+1eS5/U6pFwHJJbyOxh7/YtJ45juMMgv58lbYm7077eeDJKtkM4AGSm9CDY5XSDuvqnowHjXIcZ7jo9DvtvGXsZwKPkniMHGRmB5E4mx9kZtEBG/Aof47jjBidHi0xbxn7lyQtAS6S9DRwHu17ro7jjAJGvfdIyt3vBOA2YGLTe+U4jjNIOt08Uth7xMyWSbqNJKyg0yZ0uPdTR9HZQ83w0enX0QNGOY7TUfR3+LDtAaMcx+koOt2mnec9Mhf4BUnAqE1mdiew3czuaqegUY7jjB4qWOHSjuR5j1RIPEeuC68b8uo4rUV7fi0dZ/B0+nfeA0Y5jtNRtOsddFE8YJTjOB3FaJ+IdBzHaSs6fSLSB23HcTqKWomvO4W63iOS5kr6qaRvSZol6TZJmyTdFyL91aq3SNL9ku6vVF5ufK8dx3FqUClRiiCpW9IvJf1neD8ljIWPhdf9UrrnSFot6VFJx6XkR0haEfZdLGnQ697yXP4uAb5AYsf+OfBNM5tMkpH4klqVPGCU4zgjRcWscCnIGcCq1PuzgdvNbA5we3iPpMOAhcDhwHzgEkndoc6lJJFP54Qyf7DnlzdojzGzW8zsWsDM7HqSjduB8YNt1HEcp1k0MspfyI97PMkCwwEWAFeF7R0Np50AAA1mSURBVKuAE1PyJWa2w8weB1YD8yQdAEwys7stScp7dapOafIG7VckHSvpJMAknRhO5Cg6P9a44zhtSD+VwiVtyg1lUdXhvkoSojptTZluZusAwuv+QT4DeDql1xtkM8J2tXxQ5E1EngZcGDp8HHCapCuAtYQkB47jOK1EGe8RM1sMLI7tk/QB4Fkz+4WkowscLmantjryQZG3IvJBksF6gDMkTTGzvxhsg47jOM2kgYtr3gWcIOmPSczBkyR9C9gg6QAzWxdMHwM5c3uBWan6M0lucHvDdrV8UOR5jyyrLsCfpLYdx3FaCivxV/c4ZueY2Uwzm00ywXiHmf05sAw4JaidAtwctpcBCyWNk3QQyYTj8mBC2SLpyOA1cnKqTmnyzCOzgJV4lD/HcdqEYVhccwGwVNKpwFPASQBmtlLSUpLIqH3A6WY2MPd3GnAlMAG4JZRBIavj9iKpi8Td5Y+Bz5nZg5LW1MsPWU3P2BnD5ule1PGxVocaanhyHKc0fTufGXLejj/5nQ8W/rf93lPfb7s8IR0T5a/trrzjOE2hr8NvtTzKn+M4HUWnL2P3KH+O43QUHpq1TWjEx9TZH7XjjA7qzdN1Ah0zaDuO40Dnh2bN89OeJOlfJV0j6WNV+2oGjPIof47jjBRllrG3I3mxR64gccy4gcRp/AZJ48K+I2tV8ih/juOMFGZWuLQjeeaRQ8zsQ2H7JknnAndIOqHJ/XIcxxkUo30icpykruCvjZmdL6kX+Bmwd9N75ziOU5JOd/nLM498H3hPWmBmVwGfBXY2q1OO4ziDpQlJEFqKvBWRZ6bfS/pvwDzgoZC1wXEcp6Voz6G4OHneI8tT258AvgHsA5wn6ewm981xHKc0fVQKl3Ykz6Y9JrW9CHifmT0n6UvAPSTRrhzHcVqGdvUKKUreoN0VMg13kUQEfA7AzF6W1Nf03jmO45RktHuPTAZ+QeKrbZJea2brJe2NB9ZzHKcF6XTvkbyJyNk1dlWAP2l4bxzHcYZIp5tH8lz+opjZtpAi3nEcp6WoYIVLPSTNkvRTSaskrZR0RpBPkXSbpMfC636pOudIWi3pUUnHpeRHSFoR9l0c0o4NitKDtqSpg23McRyn2fRbpXDJoQ/4rJn9LknYjtMlHQacDdwe3J5vD+8J+xYChwPzgUskdYdjXUrizDEnlPmDPb88l78LJE0L23MlrQHulfSkpKMG26jjOE6zaGBi33Vm9kDY3gKsAmYAC4CrgtpVwIlhewGwxMx2BEvEamBeyNg+yczutsR2c3WqTmny7rSPN7Pnw/YXgY+Y2euB91Enua9H+XMcZ6QosyIyPVaFsih2TEmzgbcB9wLTQ4Z1wuv+QW0G8HSqWm+QzQjb1fJBkeunLanHzPqACWZ2X+job1LR/jKY2WJgMQxvYl/HcZwy3iPpsaoWwVvuBuAzZra5jjm6Vm7whuYMzxu0/w34oaQLgFslfRW4ETgGeHCwjTqO4zSLRsYUkTSGZMD+tpndGMQbJB1gZuuC6ePZIO8FZqWqzwTWBvnMiHxQ1DWPmNnXgc8DnySx1xxDYnR/BvirwTbqOI7TLBo1ERk8PC4DVpnZV1K7lgGnhO1TgJtT8oWSxkk6iGTCcXkwoWyRdGQ45smpOqXJTTdmZncCd4aT+EOSgFFPmNmuwTbqOI7TLBq4uOZdwF8AKyQNWBb+kSR8x1JJpwJPAScBmNlKSUuBh0k8T043s/5Q7zTgSmACcEsog0L1HNElLTezeWH7r4HTgZuAY4Hvm1lu7BG3aTuOU5S+nc8MeaX1IdPeXnjM+e3zD7Tdyu4875F0wKhPAsea2T+TDNp/1rReOY7jDJJGufy1Kh4wynGcjsLyF820NR4wynGcjmJUR/nzgFGO47QbBZantzW53iMxzGwb4AGjHMdpOTo9yt+gBm3HcZxWpV0T9hbFB23HcTqKdvUKKUpelL/JIdLfI5JeCGVVkO1bp54HjHIcZ0Qws8KlHcnz014KbASONrOpZjYVeHeQXVerkpktNrO5Zja3q2uvxvXWcRwnh0YlQWhV8lZEPmpmbyi7L42viHQcpyiNWBE5ZZ85hcecF7c81nauy3l32k9KOlPS9AGBpOmSzmLPuLGO4zgtwWg3j3wEmArcJWmjpBdJgkdNAf60yX1zHMcpTaebR/IG7UOBz5vZG0kyLXwD+G3Y11+zluM4zggx2u+0LwcG3D++CuxDEpZwG3BFE/vlOI4zKMqkG2tHcgNGhVRjAHPN7O1h+/+l4ss6juO0DJ2+jD3vTvshSR8P27+SNBdA0qGAJ0FwHKflGO3mkb8GjpL0W+Aw4G5Ja4B/D/scx3FailEdT9vMNgF/KWkf4OCg32tmG4ajc47jOGVp1zvoohSKPWJmW4BfNbkvjuM4Q6bTB+1S9p+hFmBRo3Wbccx2ar+d+jrS7bdTX0e6/Vboq5ca13BYG4P7G63bjGO2U/vt1NeRbr+d+jrS7bdCX73ES95EpOM4jtNC+KDtOI7TRgz3oL24CbrNOGY7tV9Gd7S3X0Z3tLdfRrdZ7TsR6oZmdRzHcVoLN484juO0ET5oO47jtBE+aDuO47QRTc3GLumNwAKSWNwGrAWWmdmqiN4M4F4z25qSzzezW3PauNrMTo7I3wmsMrPNkiYAZwNvBx4miRG+KeiNBRYCa83sJ5I+BvwBsApYbGYeGMtxnJahaRORISXZR4ElQG8QzyQZIJeY2QVB79PA6SSD5FuBM8zs5rDvAdsdDhZJy6qbIUk0fAeAmZ2Q0l0JvMXM+iQtJokBfj1wTJD/96D3bZIfr4nAS8DewI1BT2Z2SkMuiIOk/c3s2YK6U83shWb3qREUPa9OPKeg2zbn1RE0a9UO8BtgTEQ+Fngs9X4FsHfYng3cTzJwA/yyqu4DwLeAo4Gjwuu6sH1Ule6qdL2qfQ+mtn8dXnuADUB3eK+BfSNRgP1L6E4dYluTSZJbPAK8EMqqINs3pTcJ+FfgGuBjVce4pOr9lKoyFXgC2A+YUqV7ATAtbM8F1gCrgScjn+tc4KfhezALuA3YBNwHvK3sOTXrvJpxTu30WZU5Jy8l/1+bduDkS/W6iPx1wKOp9w9X7d8buBX4CqnBNezrAv4+fAHeGmRrarR/HfDxsH0FSRIHSFKo3ZfSe4jkh2Q/YMvAlxQYT2rgT+l33D8N8CPgLOC1Kdlrg+y2lOyG0P6JwLLwflzYV/3DWAEeryq7wuuaKt0Vqe2fAu9IfVb3V+kuB95P8hT3NPDhID8GuLvsOTXrvJpxTu30WZU5Jy/lSvMODPNJBpNbSBzqF5MMxquB+Sm9OwgDcErWA1wN9Nc49kySQfkbwFM1dCYDV5LktLw3fAnXAHeRmEcG9P4+yJ8EPg3cThIvfAVwXuS4HfdPQ+pHNHK+6R/Y6h/Rc4H/IvmRqT6nfwif95tTssdrtPEI0BO276l1vuH9L1PbT9XZV+icmnVezTindvqsypyTl3KluQdP7oyPBD4EfDhsd1fpzCQ1AFbte1fO8Y8nmVSsp7MP8BbgCGB6DZ0DgQPD9r6hr/Nq6HbcPw3wY+DM9PUBppP8EP0kJVtFkoIuXfcUYCXwZKSvAz+uXwmfQ62nok+FPrwH+CeSfKR/BPwzcE2V7t3AscBJJD+0Jwb5Uez5o1XonJp1Xs04p3b6rMqck5dyZcQ70G6lE/9pSMwwF5L8IGwEXgz9v5A97bRfAN4b6dN8UvMUkf0fBO4B1tfRORr4LvBLkqecHwKLqJoXIfkB/hHJE9wbga+RTCCvBP6g7Dk187yGeE4bwzm9q0q3+rw2hvP6QoM+qxMKfFbvjpzXJ9PnReJUUOicvJQrI96BditV/zQvVg0G+6X0RmKA60npFBrcUvpvBN5LmBRO9zeid0xE7/01jnkMyTzFBOBNsWPmHDem+7tFdIF57DYfHQ58FvjjGtc0rXsY8D8K6r4Z+J8x3ZLtv7OobqTuNQX1ri6oNwG4rsT/RNHjFuqnl/rFY480EEkfN7MrhqoX/MoPMbOHih5zKO0XdbuU9Cng7/L0yhxzkLp/S/KjWa+v55HY9HtIJmHnkcxnvBf4kZmdnzpmte47gTsL6kaPO8T26+lWu71C8tS1h9trSffYQsccYvs1j+mUZKR/NTqpUGNSdLB6zdKt1qOg22VRvVbQDXrdJP73m4FJQT6BKlfOZug2sf1Cbq8kT2FF3WPLuNI2vH0v5UpTV0R2IpJ+XWsXiW27lF6zdMsck2RyeCuAmT0h6WjgekmvC/pl9VpBt8/M+oFtkn5rZptDne2SKlXHbIZus9qfC5xBMrH9OTN7UNJ2M7urSu+Ignpljtms9p0S+KBdnunAcSSTKmkE/HwQes3SLXPM9ZLeamYPApjZVkkfAC4nsdmW1WsF3Z2SJprZNpIBJDl5aTKJiyVN1m1K+2ZWAS6SdF143UDk/7ioXrN0yxzTKclI3+q3WwEuA/5bjX3fKavXLN2SxyzkdllUrxV0CT7xEZ1ppFwrm6XbrPYjOrlur2X0mqVb5phe6hefiHQcx2kjPDSr4zhOG+GDtuM4Thvhg7bjOE4b4YO24zhOG/H/Ae4uACXg9O1JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "id = 6\n",
    "print(classmap[data[id][\"label\"]])\n",
    "sns.heatmap(data[id][\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def sample_to_frames(\n",
    "    t_sample,\n",
    "    frame_size=10, # ms / frame\n",
    "    sampling_rate=44100\n",
    "):\n",
    "    t_sec = t_sample / sampling_rate  # (sample) / (sample / sec)\n",
    "    t_frame = t_sec / (frame_size / 1000) # (sec) / (sec / 1000*frame)\n",
    "    return int(t_frame)\n",
    "\n",
    "\n",
    "def get_data(set_name=\"train\", n_notes=88):\n",
    "    # check if set_name is valid or not\n",
    "    if set_name.lower().strip() not in [\"train\", \"test\"]:\n",
    "        raise NameError(f\"Unrecognized set name: {set_name}\")\n",
    "    \n",
    "    wav_paths = sorted(glob(f\"{MUSICNET_DIR}/{set_name}_data/**/*.wav\", recursive=True))\n",
    "    csv_paths = [wav.replace(\"_data\", \"_labels\").replace(\".wav\", \".csv\") for wav in wav_paths]\n",
    "    #print(csv_paths)\n",
    "    assert all(os.path.exists(csv) for csv in csv_paths)\n",
    "    \n",
    "    data = []\n",
    "    for wav_path, csv_path in tqdm(zip(wav_paths, csv_paths), total=len(wav_paths)):\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        # config feature here\n",
    "        fbank = kaldi.fbank(wav, sample_frequency=sr, num_mel_bins=120, frame_length=30)\n",
    "        \n",
    "        label = pd.read_csv(csv_path)\n",
    "        y = np.zeros([fbank.shape[0], n_notes])\n",
    "        for  i, row in label.iterrows():\n",
    "            y[sample_to_frames(row[\"start_time\"]):sample_to_frames(row[\"end_time\"]), row[\"note\"] - 20] = 1\n",
    "            \n",
    "        data.append({\"wav_path\": wav_path, \"label\": y, \"feature\": fbank})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSoundDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n",
    "        path = os.path.join(self.audio_dir, fold, self.annotations.iloc[\n",
    "            index, 0])\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "There are 8732 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ANNOTATIONS_FILE = \"D:\\\\AI_pitch_Data\\\\UrbanSound8K\\\\metadata\\\\UrbanSound8K.csv\"\n",
    "    AUDIO_DIR = \"D:\\\\AI_pitch_Data\\\\UrbanSound8K\\\\audio\"\n",
    "    SAMPLE_RATE = 22050\n",
    "    NUM_SAMPLES = 22050\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device {device}\")\n",
    "\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
    "                            AUDIO_DIR,\n",
    "                            mel_spectrogram,\n",
    "                            SAMPLE_RATE,\n",
    "                            NUM_SAMPLES,\n",
    "                            device)\n",
    "    print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "    signal, label = usd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(usd, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CNNNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(128 * 5 * 4, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CNNNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
    "  for inputs, targets in data_loader :\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "  \n",
    "  #calculate loss\n",
    "  pred = model(inputs)\n",
    "  loss = loss_fn(pred, targets)\n",
    "  #acc = Acc_fn(pred, targets)\n",
    "\n",
    "  #backpropagate + update weight\n",
    "  optimiser.zero_grad() #ลบ gradiun จาก batch ก่อนๆ\n",
    "  loss.backward()\n",
    "  optimiser.step()\n",
    "\n",
    "  print(f\"Loss : {loss.item()}\") #\\t Acc:{acc}\")\n",
    "\n",
    "def train(model, data_loader, loss_fn, optimiser, device, epoch):\n",
    "  for i in range(epoch):\n",
    "    print(f\"Epoch : {i+1}\")\n",
    "    train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
    "    print(\"---------------------------\")\n",
    "  print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataloader, loss_fn, optimiser, device, epochs)\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Trained feed forward net saved at feedforwardnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9bf447bc3f95dcfbc19cb1a84d6b160112105653e59c16eb73ab72854d9f644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
