{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_path=\"processed_dataset\\\\train\\\\feat\\\\\"\n",
    "train_label_path=\"processed_dataset\\\\train\\\\label\\\\\"\n",
    "test_feat_path=\"processed_dataset\\\\test\\\\feat\\\\\"\n",
    "test_label_path=\"processed_dataset\\\\test\\\\label\\\\\"\n",
    "\n",
    "train_name=os.listdir(train_feat_path)\n",
    "test_name=os.listdir(test_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData() : \n",
    "    data = torch.from_numpy(np.load(path))\n",
    "    return data\n",
    "    #label = torch.from_numpy(np.load(label_path + item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Both extensions and is_valid_file cannot be None or not None at the same time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-b56d7e4b88cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m training_data = datasets.DatasetFolder(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"processed_dataset\\\\train\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WINDOW X\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WINDOW X\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\WINDOW X\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mboth_something\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextensions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_valid_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mboth_none\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mboth_something\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Both extensions and is_valid_file cannot be None or not None at the same time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Both extensions and is_valid_file cannot be None or not None at the same time"
     ]
    }
   ],
   "source": [
    "status=1\n",
    "\n",
    "training_data = datasets.DatasetFolder(\n",
    "    root=\"processed_dataset\\\\train\\\\\",\n",
    "    loader=(),\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.DatasetFolder(\n",
    "    root=\"processed_dataset\\\\test\\\\\",\n",
    "    loader=LoadData(),\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat = np.load(feat_path + item)\n",
    "        label = np.load(label_path + item)\n",
    "        if self.transform:\n",
    "            feat = self.transform(feat)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return feat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self, feat_path=train_feat_path , label_path=train_label_path , transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(train_feat_path)\n",
    "        self.feat_path = feat_path \n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (torch.from_numpy(np.load(self.feat_path +self.img_labels[idx])))\n",
    "        label = (torch.from_numpy(np.load(self.label_path +self.img_labels[idx])))\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, feat_path=test_feat_path , label_path=test_label_path , transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(train_feat_path)\n",
    "        self.feat_path = feat_path \n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = (torch.from_numpy(np.load(self.feat_path +self.img_labels[idx])))\n",
    "        label = (torch.from_numpy(np.load(self.label_path +self.img_labels[idx])))\n",
    "        '''\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        '''\n",
    "        print(self.feat_path +self.img_labels[idx])\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomTrainDataset()\n",
    "test_dataset=CustomTrainDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'yield' outside function (<ipython-input-46-5f3764ea4fcb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-5f3764ea4fcb>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    yield collate_fn([next(dataset_iter) for _ in indices])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'yield' outside function\n"
     ]
    }
   ],
   "source": [
    "dataset_iter = iter(dataset)\n",
    "for indices in batch_sampler:\n",
    "    yield collate_fn([next(dataset_iter) for _ in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "type(label)\n",
    "#print(\"Label: \",labels_map[f\"label\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9bf447bc3f95dcfbc19cb1a84d6b160112105653e59c16eb73ab72854d9f644"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
