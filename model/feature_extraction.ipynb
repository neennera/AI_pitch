{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef6cb0a-21f4-477f-8ae5-bbcfc6755a9a",
   "metadata": {},
   "source": [
    "## MusicNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8d6e6d-c4ab-4368-ae77-3d42c80e943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSICNET_DIR = \"musicnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899b045-85f2-4d13-b80e-bf2e6867438e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aff1ce9-a81b-435a-bed1-a4f44d6d35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def sample_to_frames(\n",
    "    t_sample,\n",
    "    frame_size=10, # ms / frame\n",
    "    sampling_rate=44100\n",
    "):\n",
    "    t_sec = t_sample / sampling_rate  # (sample) / (sample / sec)\n",
    "    t_frame = t_sec / (frame_size / 1000) # (sec) / (sec / 1000*frame)\n",
    "    return int(t_frame)\n",
    "\n",
    "\n",
    "def get_data(set_name=\"train\", n_notes=88):\n",
    "    # check if set_name is valid or not\n",
    "    if set_name.lower().strip() not in [\"train\", \"test\"]:\n",
    "        raise NameError(f\"Unrecognized set name: {set_name}\")\n",
    "    \n",
    "    wav_paths = sorted(glob(f\"{MUSICNET_DIR}/{set_name}_data/**/*.wav\", recursive=True))\n",
    "    csv_paths = [wav.replace(\"_data\", \"_labels\").replace(\".wav\", \".csv\") for wav in wav_paths]\n",
    "    assert all(os.path.exists(csv) for csv in csv_paths)\n",
    "    \n",
    "    data = []\n",
    "    for wav_path, csv_path in tqdm(zip(wav_paths, csv_paths), total=len(wav_paths)):\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        # config feature here\n",
    "        fbank = kaldi.fbank(wav, sample_frequency=sr, num_mel_bins=120, frame_length=30)\n",
    "        \n",
    "        label = pd.read_csv(csv_path)\n",
    "        y = np.zeros([fbank.shape[0], n_notes])\n",
    "        for  i, row in label.iterrows():\n",
    "            y[sample_to_frames(row[\"start_time\"]):sample_to_frames(row[\"end_time\"]), row[\"note\"] - 20] = 1\n",
    "            \n",
    "        data.append({\"wav_path\": wav_path, \"label\": y, \"feature\": fbank})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4845eef4-0797-49a1-a322-74893f7fef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6522336c58347cd87e54020e01431c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd4293abda54ae3ba0e79bab10d77d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_data(\"train\")\n",
    "test = get_data(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536ed92-c1b0-4741-a84d-18ce9bce7625",
   "metadata": {},
   "source": [
    "## Preprocess (split+pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e0154e5-9c4e-497f-9f7f-5d2f66bb3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 15  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fe0ccc06-778f-4e0e-be4d-20140be1595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_front_label(x):\n",
    "    \"\"\"x is 2darray\"\"\"\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i].sum() == 0:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return i, x[i:]\n",
    "            \n",
    "\n",
    "def trim_data(feature, label):\n",
    "    \"\"\"Trim wav/label where got no notes\n",
    "    \"\"\"\n",
    "    \n",
    "    idx, trimmed_front_label = trim_front_label(label)\n",
    "    trimmed_front_feature = feature[idx:]\n",
    "    \n",
    "    rev_feature = trimmed_front_feature[::-1]\n",
    "    rev_label = trimmed_front_label[::-1]\n",
    "    \n",
    "    idx, trimmed_label = trim_front_label(rev_label)\n",
    "    trimmed_feature = rev_feature[idx:]\n",
    "    return trimmed_feature[::-1], trimmed_label[::-1]\n",
    "\n",
    "\n",
    "def preprocess_set(data, max_len, trim=True):\n",
    "    dataset = {}\n",
    "    max_len = max_len * 100  # frame size 10 ms\n",
    "    for item in tqdm(data):\n",
    "        # unpack\n",
    "        feature, label = item[\"feature\"].numpy(), item[\"label\"]\n",
    "        name = os.path.basename(item[\"wav_path\"]).split(\".\")[0]\n",
    "        \n",
    "        # trim silences\n",
    "        if trim:\n",
    "            feature, label = trim_data(feature, label)\n",
    "        \n",
    "        seq_len = feature.shape[0] \n",
    "        n_samples = int(seq_len / max_len) + 1  # ceil\n",
    "        \n",
    "        # iterate over chunks\n",
    "        for i in range(n_samples):\n",
    "            start_idx = i*max_len\n",
    "            end_idx = min(start_idx + max_len, feature.shape[0])\n",
    "            \n",
    "            x_chunk = feature[start_idx:end_idx]\n",
    "            y_chunk = label[start_idx:end_idx]\n",
    "            \n",
    "            if x_chunk.shape[0] != max_len:\n",
    "                # pad remainders, will skip for now\n",
    "                continue\n",
    "                \n",
    "            if name not in dataset.keys():\n",
    "                dataset[name] = []\n",
    "            dataset[name].append({\n",
    "                \"feature\": x_chunk,\n",
    "                \"label\": y_chunk\n",
    "            })\n",
    "                \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a800765-70ad-445f-9051-1ad37227a4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec70b967e774c789b7de3eaf7bc70ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ae454f50ba429a92a9a259b5a8add0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocess_set(train, MAX_LEN)\n",
    "test_data = preprocess_set(test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdbd72-0bb5-4919-9b76-fb546831547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"1727\"\n",
    "item_no = 0\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n",
    "ax[0].imshow(train_data[data_id][item_no][\"feature\"].T)\n",
    "ax[1].imshow(train_data[data_id][item_no][\"label\"].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b17d26ae-2f9e-41e1-afa8-43c07978cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(data, save_path):\n",
    "    os.makedirs(os.path.join(save_path, \"feat\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path, \"label\"), exist_ok=True)\n",
    "    for name, d in data.items():\n",
    "        for i, item in enumerate(d):\n",
    "            with open(f\"{save_path}/feat/{name}-{i:02d}.npy\", \"wb\") as f:\n",
    "                np.save(f, item[\"feature\"].astype(np.float32))\n",
    "                \n",
    "            with open(f\"{save_path}/label/{name}-{i:02d}.npy\", \"wb\") as f:\n",
    "                np.save(f, item[\"label\"].astype(np.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8ec2d-8496-4a3a-bfbc-3f757c599a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_dataset(train_data, \"processed_dataset\")\n",
    "dump_dataset(test_data, \"processed_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "67cb54a4-bd84-4b84-8255-2cef9c193b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3G\tprocessed_dataset/feat\n",
      "3.9G\tprocessed_dataset/label\n",
      "9.2G\tprocessed_dataset\n"
     ]
    }
   ],
   "source": [
    "!du -h processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693d3a1-2223-4954-a6fb-a7c1d2df8d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9bf447bc3f95dcfbc19cb1a84d6b160112105653e59c16eb73ab72854d9f644"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
