{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "figure(figsize=(12, 8), dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from torchaudio.compliance import kaldi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def sample_to_frames(\n",
    "    t_sample,\n",
    "    frame_size=10, # ms / frame\n",
    "    sampling_rate=44100\n",
    "):\n",
    "    t_sec = t_sample / sampling_rate  # (sample) / (sample / sec)\n",
    "    t_frame = t_sec / (frame_size / 1000) # (sec) / (sec / 1000*frame)\n",
    "    return int(t_frame)\n",
    "\n",
    "\n",
    "def get_data(set_name=\"train\", n_notes=88):\n",
    "    # check if set_name is valid or not\n",
    "    if set_name.lower().strip() not in [\"train\", \"test\"]:\n",
    "        raise NameError(f\"Unrecognized set name: {set_name}\")\n",
    "    \n",
    "    wav_paths = sorted(glob(f\"{MUSICNET_DIR}/{set_name}_data/**/*.wav\", recursive=True))\n",
    "    csv_paths = [wav.replace(\"_data\", \"_labels\").replace(\".wav\", \".csv\") for wav in wav_paths]\n",
    "    #print(csv_paths)\n",
    "    assert all(os.path.exists(csv) for csv in csv_paths)\n",
    "    \n",
    "    data = []\n",
    "    for wav_path, csv_path in tqdm(zip(wav_paths, csv_paths), total=len(wav_paths)):\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        # config feature here\n",
    "        fbank = kaldi.fbank(wav, sample_frequency=sr, num_mel_bins=120, frame_length=30)\n",
    "        \n",
    "        label = pd.read_csv(csv_path)\n",
    "        y = np.zeros([fbank.shape[0], n_notes])\n",
    "        for  i, row in label.iterrows():\n",
    "            y[sample_to_frames(row[\"start_time\"]):sample_to_frames(row[\"end_time\"]), row[\"note\"] - 20] = 1\n",
    "            \n",
    "        data.append({\"wav_path\": wav_path, \"label\": y, \"feature\": fbank})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSICNET_DIR = \"D:\\\\AI_pitch_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fb2b7882d94cc98d80bcc7474be320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = get_data(\"train\")\n",
    "#test = get_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"testJS.json\",\"wb\") as ff:\n",
    "    #pickle.dump(test,ff)\n",
    "with open(\"trainJS.json\",\"wb\") as ff:\n",
    "    pickle.dump(train,ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"testJS.json\",\"rb\")\n",
    "test=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"trainJS.json\",\"rb\")\n",
    "train=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (split+pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 15  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_front_label(x):\n",
    "    \"\"\"x is 2darray\"\"\"\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i].sum() == 0:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return i, x[i:]\n",
    "            \n",
    "\n",
    "def trim_data(feature, label):\n",
    "    \"\"\"Trim wav/label where got no notes\n",
    "    \"\"\"\n",
    "    \n",
    "    idx, trimmed_front_label = trim_front_label(label)\n",
    "    trimmed_front_feature = feature[idx:]\n",
    "    \n",
    "    rev_feature = trimmed_front_feature[::-1]\n",
    "    rev_label = trimmed_front_label[::-1]\n",
    "    \n",
    "    idx, trimmed_label = trim_front_label(rev_label)\n",
    "    trimmed_feature = rev_feature[idx:]\n",
    "    return trimmed_feature[::-1], trimmed_label[::-1]\n",
    "\n",
    "\n",
    "def preprocess_set(data, max_len, idl, idr, trim=True):\n",
    "    dataset = {}\n",
    "    max_len = max_len * 100  # frame size 10 ms\n",
    "    for i in range(idl,idr):\n",
    "        # unpack\n",
    "        # for i in tqdm(data)\n",
    "        item = data[i]\n",
    "        feature, label = item[\"feature\"].numpy(), item[\"label\"]\n",
    "        name = os.path.basename(item[\"wav_path\"]).split(\".\")[0]\n",
    "        \n",
    "        # trim silences\n",
    "        if trim:\n",
    "            feature, label = trim_data(feature, label)\n",
    "        \n",
    "        seq_len = feature.shape[0] \n",
    "        n_samples = int(seq_len / max_len) + 1  # ceil\n",
    "        \n",
    "        # iterate over chunks\n",
    "        for i in range(n_samples):\n",
    "            start_idx = i*max_len\n",
    "            end_idx = min(start_idx + max_len, feature.shape[0])\n",
    "            \n",
    "            x_chunk = feature[start_idx:end_idx]\n",
    "            y_chunk = label[start_idx:end_idx]\n",
    "            \n",
    "            if x_chunk.shape[0] != max_len:\n",
    "                # pad remainders, will skip for now\n",
    "                continue\n",
    "                \n",
    "            if name not in dataset.keys():\n",
    "                dataset[name] = []\n",
    "            dataset[name].append({\n",
    "                \"feature\": x_chunk,\n",
    "                \"label\": y_chunk\n",
    "            })\n",
    "                \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(300,320,10) :\n",
    "    train_data = preprocess_set(train, MAX_LEN,i,i+10)\n",
    "    dump_dataset(train_data, \"processed_dataset\")\n",
    "    print(i)\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## untouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_set(train, MAX_LEN)\n",
    "test_data = preprocess_set(test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_id = \"1727\"\n",
    "item_no = 0\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n",
    "ax[0].imshow(train_data[data_id][item_no][\"feature\"].T)\n",
    "ax[1].imshow(train_data[data_id][item_no][\"label\"].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dump part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(data, save_path):\n",
    "    os.makedirs(os.path.join(save_path, \"feat\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path, \"label\"), exist_ok=True)\n",
    "    for name, d in data.items():\n",
    "        for i, item in enumerate(d):\n",
    "            with open(f\"{save_path}/feat/{name}-{i:02d}.npy\", \"wb\") as f:\n",
    "                np.save(f, item[\"feature\"].astype(np.float32))\n",
    "                \n",
    "            with open(f\"{save_path}/label/{name}-{i:02d}.npy\", \"wb\") as f:\n",
    "                np.save(f, item[\"label\"].astype(np.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dataset(train_data, \"processed_dataset\")\n",
    "#dump_dataset(test_data, \"processed_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h processed_dataset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9bf447bc3f95dcfbc19cb1a84d6b160112105653e59c16eb73ab72854d9f644"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
